## 1. 흉부 X선 이미지 데이터 불러오고 확인하기

이미지 데이터를 다루기 위한 첫번째 단계는 바로 이미지를 불러오고 원하는 크기로 조정하는 것입니다. 만약 우리가 200x200과 1200x1200 크기의 이미지 두장을 가지고 있다고 가정해봅시다. 이 둘을 하나의 모델로 처리하기 위해서는 크기를 맞춰주어야할 것입니다.

해당 실습에서는 흉부 X선 이미지 데이터를 불러오고 이미지의 크기를 절반으로 줄이는 작업을 해보겠습니다.

이미지 데이터는 픽셀(Pixel)이라고 작은 정보 요소의 집합입니다. 또한, 이러한 이미지 데이터는 숫자로 이루어진 커다란 행렬로 볼 수 있습니다.

이번 실습에서는 PIL, Numpy 라이브러리를 이용하여 이미지를 불러오고 Numpy 행렬로 변환해 보겠습니다.

실습은 `data` 폴더의 `images` 폴더 안에 10장의 이미지 중 ***\*하나의 이미지\****를 이용하여 진행하겠습니다.

### ***\*실습에서 사용하는 라이브러리/함수\****

- `PIL(Python Imaging Library)`: 이미지 분석 및 처리를 쉽게 할 수 있도록 돕는 라이브러리
- `Numpy`: 행렬과 같은 대규모 다차원 배열을 쉽게 처리할 수 있도록 돕는 라이브러리



------

### 실습에 활용된 데이터셋

본 실습에서는 샌 디에고 대학에서 공개한 오픈 데이터셋을 활용합니다.

[Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), “Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification”, Mendeley Data, V2, doi: 10.17632/rscbjbr9sj.2](https://data.mendeley.com/datasets/rscbjbr9sj/2)

## 지시사항

1. 이미지 파일의 경로를 변경해 이미지파일을 불러오세요.

- - 상대경로를 이용해 이미지 파일이 있는 폴더의 경로를 IMG_PATH에 입력하세요.
  - CSV_PATH에 입력된 경로를 참고하여 작성하세요.

1. 이미지 크기를 조정하여 크기를 조정하세요.

- - 이미지 크기가 150*150이 되도록 `IMG_SIZE`를 변경하세요.

## ***\*Tips!\****

원본 이미지의 크기와 resize 후의 이미지 크기(1-1, 1-2에 해당)를 비교해보세요. 그리고 원본 이미지와 resize된 이미지(2-1, 2-2에 해당)와 비교해보세요.



## 2. 흉부 X선 이미지 히스토그램 그리기

이번 실습에서는 matplotlib 라이브러리를 이용해 이미지의 히스토그램을 계산하고 시각화해보겠습니다.

이미지 히스토그램은 디지털 이미지에서 색 분포를 그래픽으로 표현하는 역할을 합니다. 이를 위해 각 색 값(혹은 범주)에 대한 픽셀 수를 표시합니다. 특정 이미지에 대한 히스토그램을 통해 우리는 전체 색 분포를 한 눈에 판단할 수 있습니다.

이러한 이미지 히스토그램은 많은 분야에 활용됩니다. 너무 어두워 잘 보이지 않는 사진을 잘 보이게 하거나 전체 이미지의 톤을 변경하는 등 다양하게 활용될 수 있습니다.

### ***\*히스토그램의 정의\****

히스토그램은 수치 데이터의 분포를 그래프로 표현한 것입니다. 따라서 이미지의 히스토그램은 이미지를 구성하는 픽셀값 분포에 대한 그래프를 말합니다. X축은 그레이 레벨(대체로 0에서 256까지)을 Y축은 이미지의 해당 그레이 레벨에 해당하는 픽셀의 수를 나타내게 됩니다.

우리는 히스토그램을 통해 그레이 레벨에 따른 픽셀 분포를 한눈에 확인할 수 있고, 이를 통해 이미지의 특성을 알 수 있습니다.

### ***\*라이브러리\****

- `cv2(OpenCV)`: 인텔에서 개발한 실시간 이미지 처리를 위한 라이브러리
- `matplotlib`: 시각화를 위한 종합적인 라이브러리

### ***\*함수\****

**`\**cv.calcHist(images, channels, mask, histSize, ranges)\**`*****\*: 이미지의 히스토그램을 계산하여 주는 함수입니다.\****

1. `images`: 히스토그램을 계산하고자 하는 이미지 입니다. 여러 개의 이미지일 경우 리스트(list) 형식으로 입력하세요.
2. `channels`: 히스토그램을 계산할 채널의 인덱스를 지정합니다. 흑백 이미지의 경우 [0]을, 컬러(빨강, 초록 및 파랑) 이미지에 대한 히스토그램을 계산하려면 [0, 1, 2]를 입력하세요.
3. `mask`: 계산하고자하는 이미지 영역을 지정합니다. 전체 영역에 대한 계산을 원할 경우 None을 입력하세요.
4. `histSize`: 히스토그램 계산 시 사용하는 빈(bin)의 수를 의미합니다.
5. `ranges`: 계산하고자하는 그레이 레벨(명암)의 범위입니다. 일반적으로 [0, 256]을 사용합니다.

**`\**cv.bitwise_and(image1, image2, mask)\**`*****\*: 두 이미지의 서로 공통으로 겹치는 부분 출력하는 함수입니다.\****

1. `image1, image2`: 사용할 두 개의 이미지를 입력하세요.
2. `mask`: 계산하고자하는 이미지 영역을 지정합니다. 전체 영역에 대한 계산을 원할 경우 None을 입력하세요.



------

### 실습에 활용된 데이터셋

본 실습에서는 샌 디에고 대학에서 공개한 오픈 데이터셋을 활용합니다.

[Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), “Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification”, Mendeley Data, V2, doi: 10.17632/rscbjbr9sj.2](https://data.mendeley.com/datasets/rscbjbr9sj/2)

## 지시사항

1. `channels`에 적절한 값을 입력하세요. 실습에서 사용하는 이미지는 흑백(그레이 스케일) 이미지 입니다.
2. 모든 그레이 레벨(명암)을 사용하도록 `ranges` 범위를 조정하세요. 그레이 레벨은 ***\*0부터 255까지\****의 값입니다.
3. `x_range`와 `y_range`내 범위를 조정하여 전체 이미지의 오른쪽 아래 1/4에 대한 히스토그램을 구하세요. 이미지의 가로 크기인 `width` 와 세로 크기인 `height`를 활용합니다. 예를 들어 가로의 경우 `width`를 2로 나눈 몫 부터 `width`까지의 값을 지정하면 됩니다.



## 3. 이미지 증강 기법(Data Augmentation)을 이용하기

이번 실습에서는 이미지 증강 기법을 이용해 이미지 데이터의 개수를 늘려보겠습니다.

대부분의 딥러닝 모델의 성능은 훈련 데이터의 품질, 수량 그리고 관련성에 따라 달라집니다. 특히 적은 데이터는 모델의 성능을 저해하는 대표적인 원인 중 하나입니다. 하지만 많은 경우, 데이터를 수집하는 데는 많은 비용과 시간이 소요됩니다.

데이터 증강은 이러한 문제를 완화하기 위해 기존 데이터를 이용하여 새로운 데이터를 생성하는 기술입니다. 여기에는 기존 데이터를 약간 변형하는 것이 포함됩니다.

본 실습에서 수행할 이미지를 뒤집는 증강 방식인 Flipping은 단순하지만 매우 효율적인 방식입니다.



### ***\*라이브러리\****

- `keras`: 딥러닝 모델을 쉽게 구현할 수 있도록 도와주는 파이썬 신경망 라이브러리

### ***\*데이터\****

이번 실습에서 사용할 이미지는 정상인 사람의 폐와 폐렴으로 인해 혼탁을 보이는 사람의 폐의 이미지입니다. 두 이미지는 각각 dataset 폴더에 위치한 `normal` 과 `opacity`에 있습니다.



------

### 실습에 활용된 데이터셋

본 실습에서는 샌 디에고 대학에서 공개한 오픈 데이터셋을 활용합니다.

[Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), “Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification”, Mendeley Data, V2, doi: 10.17632/rscbjbr9sj.2](https://data.mendeley.com/datasets/rscbjbr9sj/2)

## 지시사항

1. `rescale_ratio`의 값을 설정하세요.

- - 일반적으로 이미지는 0-255의 값을 가진 픽셀로 구성됩니다. 이러한 픽셀 값은 모델 학습 속도 저하와 같은 문제를 발생시킬 수 있습니다. 우리는 픽셀 값을 0-1 범위로 조정하여 표준화함으로써 이러한 문제를 완화할 수 있습니다. `rescale_ratio` 는 0-255까지의 정수로 표현된 픽셀값을 0-1값으로 변환하기 위한 비율입니다.

1. `horizontal_flip`을 사용하도록 설정하세요.

- - horizontal flip을 사용할 경우 50%의 확률로 이미지를 뒤집습니다. 우리는 단순한 뒤집기 만으로 이미지 데이터를 두 배로 늘릴 수 있습니다. `ImageDataGenerator`에서는 boolean을 통해 flip 활용 여부를 설정할 수 있습니다.

![https://dataaspirant.com/data-augmentation-techniques-deep-learning/](https://cdn-api.elice.io/api-attachment/attachment/dd880ff05287472aaf403006aedc4f03/5-horizontal-flip-technique.png)

- - 이외에도 `rotation_range`를 사용하여 이미지를 회전시키거나 `width_shift` 혹은 `height_shift`를 사용하여 이미지를 수평 혹은 수직으로 이동시킬 수 있습니다.

1. 전처리된 훈련 및 테스트 데이터 전처리기 및 데이터셋을 생성하세요.
2. - 앞서 생성한 `rescale_ratio`와`horizontal_flip`을 활용하세요.
   - 스켈레톤 코드에 주어진 `generate_dataset()` 함수의 코드를 읽어보고 활용하세요.



## 4. VGG16 구현하기

VGGNet은 ILSVRC 2014년도에 2위를 차지한 모델로, 모델의 깊이에 따른 변화를 비교할 수 있게 만든 이미지 분류 모델입니다. 간단한 구조와 높은 성능을 가지고 있어 많이 사용되는 모델입니다.

VGGNet은 모든 Convolution Layer에 3 x 3 convolution filter를 사용한 것이 특징입니다.

이전까지의 모델들은 첫 번째 Conv Layer에서는 입력 영상의 축소를 위해 11 x 11, 7 x 7의 Conv filter를 사용했습니다.

![image](https://cdn-api.elice.io/api-attachment/attachment/cb4a626dcd8540b78847e78683ce06a8/Conv_filter.png)

3 x 3 Conv filter를 두번 사용하면 (5 x 5)와 같고, 세 번 사용하면 (7 x 7) 과 같아집니다. 그러나 3 x 3을 여러번 사용하게 되면, 연산에 드는 비용이 더 적어지기 때문에 (ex, 3 x 3 x 2 = 18 vs 5 x 5 = 25) 더 높은 성능을 낼 수 있습니다.

이번 시간에는 논문에 나온 구조를 보고 keras를 이용해 비어있는 모델의 구조를 채워보겠습니다.

## 지시사항

1. 아래 표를 보고 세 번째, 네 번째 합성곱 블록을 완성하세요.

- conv3은 3x3 크기의 커널(혹은 필터)을 사용한다는 것을 의미합니다.
- 256 혹은 512는 사용하는 커널의 개수를 의미합니다.
- 활성화 함수(activation) 및 패딩(padding)은 다른 블록과 동일합니다.
  ![Image](https://cdn-api.elice.io/api-attachment/attachment/1c98e6ea3e874c32b62c6ef973b67a78/%EB%B3%B4%EC%A1%B0%20Figure1.png)

### Tips!

<details open="" class="Collapsible__container" style="overflow-wrap: break-word; word-break: keep-all; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); box-sizing: border-box; image-rendering: -webkit-optimize-contrast; border: 1px solid rgb(170, 170, 170); font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; font-family: inherit; font-optical-sizing: inherit; font-size-adjust: inherit; font-kerning: inherit; font-feature-settings: inherit; font-variation-settings: inherit; font-size: 16px; margin: 0px 0px 8px; padding: 0px; vertical-align: initial; display: block; border-radius: 4px;"><summary class="Collapsible__title" style="overflow-wrap: break-word; word-break: keep-all; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); box-sizing: border-box; image-rendering: -webkit-optimize-contrast; border-width: 0px 0px 1px; border-top-style: initial; border-right-style: initial; border-bottom-style: solid; border-left-style: initial; border-top-color: initial; border-right-color: initial; border-bottom-color: rgb(170, 170, 170); border-left-color: initial; border-image: initial; font-style: inherit; font-variant: inherit; font-weight: bold; font-stretch: inherit; line-height: inherit; font-family: inherit; font-optical-sizing: inherit; font-size-adjust: inherit; font-kerning: inherit; font-feature-settings: inherit; font-variation-settings: inherit; font-size: 16px; margin: 0px 0px 0.5em; padding: 5px 5px 5px 20px; vertical-align: initial; cursor: pointer; position: relative; list-style: none; outline: none;"><p dir="ltr" class="editor-paragraph" style="overflow-wrap: break-word; word-break: keep-all; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); box-sizing: border-box; image-rendering: -webkit-optimize-contrast; border: 0px; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: 1.5; font-family: inherit; font-optical-sizing: inherit; font-size-adjust: inherit; font-kerning: inherit; font-feature-settings: inherit; font-variation-settings: inherit; font-size: 1rem; margin: 0px; padding: 0px; vertical-align: initial; display: block; position: relative;"><span style="overflow-wrap: break-word; word-break: keep-all; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); box-sizing: border-box; image-rendering: -webkit-optimize-contrast; border: 0px; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; font-family: inherit; font-optical-sizing: inherit; font-size-adjust: inherit; font-kerning: inherit; font-feature-settings: inherit; font-variation-settings: inherit; font-size: 16px; margin: 0px; padding: 0px; vertical-align: initial; white-space: pre-wrap;">구조</span></p></summary><div data-lexical-collapsible-content="true" class="Collapsible__content" style="overflow-wrap: break-word; word-break: keep-all; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); box-sizing: border-box; image-rendering: -webkit-optimize-contrast; border: 0px; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; font-family: inherit; font-optical-sizing: inherit; font-size-adjust: inherit; font-kerning: inherit; font-feature-settings: inherit; font-variation-settings: inherit; font-size: 16px; margin: 0px; padding: 5px; vertical-align: initial;"><p dir="ltr" class="editor-paragraph" style="overflow-wrap: break-word; word-break: keep-all; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); box-sizing: border-box; image-rendering: -webkit-optimize-contrast; border: 0px; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: 1.5; font-family: inherit; font-optical-sizing: inherit; font-size-adjust: inherit; font-kerning: inherit; font-feature-settings: inherit; font-variation-settings: inherit; font-size: 1rem; margin: 0px 0px 8px; padding: 0px; vertical-align: initial; display: block; position: relative;"><span style="overflow-wrap: break-word; word-break: keep-all; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); box-sizing: border-box; image-rendering: -webkit-optimize-contrast; border: 0px; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; font-family: inherit; font-optical-sizing: inherit; font-size-adjust: inherit; font-kerning: inherit; font-feature-settings: inherit; font-variation-settings: inherit; font-size: 16px; margin: 0px; padding: 0px; vertical-align: initial; white-space: pre-wrap;">VGGNet은 VGG16, VGG19 2개의 버전이 있습니다. 숫자는 모델이 가진 레이어의 개수를 의미합니다. 예를 들어 VGG16은 13개의 합성곱 레이어(convolution layer)와 3개의 완전 연결 레이어(fully connected layer)로 구성되어 있습니다.</span><br style="overflow-wrap: break-word; word-break: keep-all; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); box-sizing: border-box; image-rendering: -webkit-optimize-contrast;"><img height="inherit" width="inherit" alt="image" src="https://cdn-api.elice.io/api-attachment/attachment/a2c34b385fa8478eb6552b893d4b08b8/vgg16.png" style="overflow-wrap: break-word; word-break: keep-all; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); box-sizing: border-box; image-rendering: -webkit-optimize-contrast; border: 0px; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; font-family: inherit; font-optical-sizing: inherit; font-size-adjust: inherit; font-kerning: inherit; font-feature-settings: inherit; font-variation-settings: inherit; font-size: 16px; margin: 0px; padding: 0.5rem; vertical-align: middle; max-width: 100%; height: auto; border-radius: 4px;"></p><p dir="ltr" class="editor-paragraph" style="overflow-wrap: break-word; word-break: keep-all; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); box-sizing: border-box; image-rendering: -webkit-optimize-contrast; border: 0px; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: 1.5; font-family: inherit; font-optical-sizing: inherit; font-size-adjust: inherit; font-kerning: inherit; font-feature-settings: inherit; font-variation-settings: inherit; font-size: 1rem; margin: 0px; padding: 0px; vertical-align: initial; display: block; position: relative;"><span style="overflow-wrap: break-word; word-break: keep-all; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); box-sizing: border-box; image-rendering: -webkit-optimize-contrast; border: 0px; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; font-family: inherit; font-optical-sizing: inherit; font-size-adjust: inherit; font-kerning: inherit; font-feature-settings: inherit; font-variation-settings: inherit; font-size: 16px; margin: 0px; padding: 0px; vertical-align: initial; white-space: pre-wrap;">Keras의 </span><code spellcheck="false" style="overflow-wrap: break-word; word-break: keep-all; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); box-sizing: border-box; image-rendering: -webkit-optimize-contrast; border: 0px; font-style: inherit; font-variant: inherit; font-weight: 700; font-stretch: inherit; line-height: inherit; font-family: &quot;Elice Digital Coding&quot;, Inconsolata, &quot;Lucida Console&quot;, &quot;Courier New&quot;, monospace !important; font-optical-sizing: inherit; font-size-adjust: inherit; font-kerning: inherit; font-feature-settings: inherit; font-variation-settings: inherit; font-size: 0.775em; margin: 0px 2px; padding: 4px 6px; vertical-align: middle; border-radius: 0.25rem; background-color: rgb(233, 235, 240); color: rgb(183, 28, 28); white-space: pre-wrap;"><span class="editor-text-code" style="overflow-wrap: break-word; word-break: keep-all; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); box-sizing: border-box; image-rendering: -webkit-optimize-contrast; border: 0px; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; font-family: Menlo, Consolas, Monaco, monospace; font-optical-sizing: inherit; font-size-adjust: inherit; font-kerning: inherit; font-feature-settings: inherit; font-variation-settings: inherit; font-size: 14px; margin: 0px; padding: 1px 0.25rem; vertical-align: initial;">summary()</span></code><span style="overflow-wrap: break-word; word-break: keep-all; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); box-sizing: border-box; image-rendering: -webkit-optimize-contrast; border: 0px; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; font-family: inherit; font-optical-sizing: inherit; font-size-adjust: inherit; font-kerning: inherit; font-feature-settings: inherit; font-variation-settings: inherit; font-size: 16px; margin: 0px; padding: 0px; vertical-align: initial; white-space: pre-wrap;">는 모델의 요약 정보를 제공합니다. VGG16의 요약정보를 보면 파라미터가 굉장히 많은 것을 확인할 수 있습니다. 모델이 커짐에 따라 더 많은 파라미터가 필요하기 때문에 Computation Power가 굉장히 커집니다. 또한, 모델이 깊어짐에 따라 아래로 갈수록 기울기가 소실되어 학습이 되지 않는 기울기 소실 문제가 발생합니다. 위의 문제로 VGGNet은 16 혹은 19 레이어 모델만을 만들었으며, 후에 기울기 소실 문제를 완화한 152층의 ResNet과 같은 모델이 등장합니다.</span></p></div></details>



- 관련 링크
- - https://arxiv.org/pdf/1409.1556.pdf





## 5. 딥러닝 학습을 위한 데이터셋 분리

이번 실습에서는 머신러닝과 딥러닝 모델 학습을 위해 데이터셋을 학습, 검증 및 테스트 세트로 나누는 작업을 진행하겠습니다.

왜 학습 데이터가 많을수록 성능이 향상되는데도 불구하고 데이터를 나눠야 할까요?

여기에 대한 대답으로는 ***\*과적합 문제\****가 있습니다.
일반적으로 모델의 파라미터가 충분할 경우, 딥러닝 모델은 학습 데이터에서 100%에 가까운 성능을 달성할 수 있습니다. 하지만 이러한 성능이 미지의 새로운 데이터에서의 성능을 보장하지는 않습니다. 결론적으로 학습 데이터가 아닌 새로운 데이터에 대해 예측 성능을 측정해야 합니다.

따라서 우리는 미지의 데이터에서의 모델 성능을 향상시키기 위해 데이터를 학습, 검증 및 테스트로 나누는 것입니다.

***\*Train 데이터:\**** 모델이 데이터의 숨겨진 기능/패턴을 학습하도록 하는 데 사용되는 데이터 세트입니다.

***\*Validation 데이터:\**** 검증 세트는 훈련 중 모델 성능을 검증하는 데 사용되는 훈련 세트와 별개의 데이터 세트입니다. 이 검증 프로세스는 모델의 하이퍼파라미터와 구성을 적절하게 조정하는 데 도움이 되는 정보를 제공합니다.

***\*Test 데이터:\**** 테스트 세트는 훈련 완료 후 모델을 테스트하는 데 사용되는 별도의 데이터 세트입니다. 간단히 말해서 " 모델이 얼마나 잘 수행됩니까? " 라는 질문에 답합니다.

### ***\*라이브러리\****

- `scikit-learn(sklearn)`: 다양한 머신러닝 알고리즘이 구현되어있는 파이썬 라이브러리로 다양한 머신러닝 실습을 위한 예제들을 포함하고 있음

### ***\*데이터 정보\****

***\*iris dataset:\**** 패턴 인식 분야에서 가장 널리 알려진 데이터셋 중 하나입니다. 데이터세트는 총 3개의 클래스와 50개의 인스턴스를 가지고 있습니다. 또한, 각 클래스는 붓꽃 식물의 유형을 나타냅니다.

학습 데이터를 확인해보면 각 예제 당 아래와 같은 네 개의 특징(feature)값을 가지고 있습니다. 각 특징은 꽃의 특성을 나타냅니다.

1. 1. 꽃받침 길이(cm)
   2. 꽃받침 너비(cm)
   3. 꽃잎 길이(cm)
   4. 꽃잎 너비(cm)

![Image](https://cdn-api.elice.io/api-attachment/attachment/997d06f0087e4ebe93e41c50e0d61cfb/irish_data.JPG)

또한 각 클래스는 아래와 같은 붓꽃 식물의 유형을 나타냅니다.

- 0: Setosa
- 1: Versicolour
- 2: Virginica

## 지시사항

1. `split_ratio`를 조정하여 학습, 검증 및 테스트 데이터 비율이 7 : 1.5 : 1.5가 되도록 하세요.
2. `merge_data()`함수를 활용하여 학습, 검증 및 테스트 데이터를 만들고 형태를 확인하세요.





## 6. 신경망 모델로 이미지 학습하기

본 실습에서는 VGG19 모델을 학습시켜보겠습니다. 이를 위해 모델에 맞게 데이터를 수정하고, 실제 학습시켜보는 실습을 진행합니다.

이번 실습을 통해 이전에 학습한 내용을 복습함과 동시에 어떠한 과정을 통해 모델이 생성되고 학습되는지에 대한 이해를 넓힙니다.

또한, 하이퍼파라미터(이미지의 크기, 학습 에폭, 에폭당 스텝 수 등)를 변경해보며 모델의 학습을 제어해보도록 하겠습니다.



***\*채점에는 5~10분 정도가 소요됩니다.\****



------

### 실습에 활용된 데이터셋

본 실습에서는 샌 디에고 대학에서 공개한 오픈 데이터셋을 활용합니다.

[Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), “Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification”, Mendeley Data, V2, doi: 10.17632/rscbjbr9sj.2](https://data.mendeley.com/datasets/rscbjbr9sj/2)

## 지시사항

- `vgg.py` 파일에는 VGG19 모델이 구현되어 있습니다. 모델을 살펴보며 이전에 구현했던 VGG16과 비교해보세요.
- VGG19 모델은 `main.py`와 다른 파일에 있지만 `import vgg`를 통해서 해당 위치에서 사용할 수 있습니다.
- 실습 지시사항은 `main.py`파일에서 수행하세요.



***\*1. VGG 모델의 입력 이미지 크기를 224x224로 변경해주세요.\****

- `input_shape`에 이미지 사이즈를 튜플로 입력해주세요.

***\*2. 학습 및 테스트 이미지의 크기를 224x224로 변경해주세요.\****

- ***\*training_set과 test_set\****의 `target_size`를 224x224로 변경하여 학습 및 테스트 이미지의 크기를 변경하세요.

***\*3. 모델을 학습 데이터에\**** **`\**fit()\**`*****\*시켜주세요.\****

- 학습 데이터는 training_set, `steps_per_epoch`는 20, `epochs`는 4, `validation_data`는 val_set으로 설정합니다.
- 실행을 눌러 모델을 학습시킨 뒤 평가 데이터에 대한 성능을 확인하세요.





## 7. Confusion Matrix를 통한 딥러닝 성능 평가하기

딥러닝 모델을 완성하였다면 테스트 세트를 활용해 모델이 잘 만들어졌는지를 평가해야 합니다. 모델의 성능은 단순히 정확도가 높다고 반드시 좋은 것은 아닙니다. 예를 들어, 암환자 진단 모델이 일반사람들을 대상으로 암환자가 아니라고 예측한 결과의 정확도가 97%라고 하였을 때, 높은 성능은 단순히 암환자가 거의 없기 때문에 달성되었을 수 있습니다.

이 경우에는 암환자라고 예측한 경우 중 실제 암환자가 얼마나 되는지가 중요할 수 있습니다. ***\*Confusion matrix\****는 분류 모델의 성능을 나타내는 정확도(accuracy), 정밀도(precision), 재현도(recall), F1 Score를 한눈에 볼 수 있도록 시각화한 테이블입니다.

이번 시간에는 정상/간질성 혼탁 두 가지 카테고리의 흉부 X선 이미지 데이터를 사용하여 VGG16 모델의 분류 성능을 확인해보겠습니다.

### ***\*TP, FP, TN, FN란?\****

- ***\*TP(True Positive):\**** 1(정답)인 레이블을 1이라고 예측한 경우
- ***\*FP(False Positive):\**** 0(오답)인 레이블을 1이라고 예측한 경우
- ***\*TN(True Negative):\**** 0(오답)인 레이블을 0이라고 예측한 경우
- ***\*FN(False Negative):\**** 1(정답)인 레이블을 0이라고 예측한 경우

### ***\*정확도, 정밀도, 재현율, F1 score\****

- ***\*정확도 (accuracy):\**** 얼마나 1을 1로, 0을 0으로 정확하게 분류해내는지

*a**cc**u**r**a**cy*=*TP*+*FP*+*FN*+*TN**TP*+*TN*

- ***\*정밀도 (precision):\**** 모델이 1이라고 분류해냈을 때 실제 얼마나 1인지. 즉, 얼마나 믿을만하게 1로 분류해내는지 평가하는 지표

*p**rec**i**s**i**o**n*=*TP*+*FP**TP*

- ***\*재현율 (recall):\**** 전체 실제 1 중에서 모델이 1이라고 올바르게 예측한 비율, 즉 1을 얼마나 잘 판단하는지 평가하는 지표

*rec**a**ll*=*TP*+*FN**TP*

- ***\*F1 score:\**** F1 score는 precision과 recall의 균형을 원할 때 사용합니다. 일반적으로 클래스 분포가 고르지 않은 경우 더 나은 측정 방법으로 많이 사용됩니다.

*F*1=2∗*P**rec**i**s**i**o**n*+*R**ec**a**ll**P**rec**i**s**i**o**n*∗*R**ec**a**ll*



### 채점에는 2~3분정도 소요됩니다.



------

### 실습에 활용된 데이터셋

본 실습에서는 샌 디에고 대학에서 공개한 오픈 데이터셋을 활용합니다.

[Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), “Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification”, Mendeley Data, V2, doi: 10.17632/rscbjbr9sj.2](https://data.mendeley.com/datasets/rscbjbr9sj/2)

## 지시사항

1. 코드 작성에 앞서 실행 버튼을 눌러 출력된 confusion_maxtrix를 확인하고 해당하는 위치를 활용하여 `tp`, `fn`, `fp`, `tn`을 구하세요.
2. `tp`, `fn`, `fp`, `tn`를 이용하여 accuracy, precision, recall, f-1 score를 구하세요.



## 8. 분류(Classification) 평가 지표

앞서 우리는 모델 성능평가를 위해 confusion matrix와 정확도, 정밀도, 재현율 및 F1 score를 구해보았습니다.

이번 시간에는 다중 클래스 분류 모델의 성능을 확인하거나 시각화할 때 사용하는 ***\*AUC\****(Area Under the Curve)와 ***\*ROC\****(Receiver Operating Characteristic curve)에 대해 알아보고 구현해 보도록 하겠습니다.

### ***\*AUC - ROC Curve\****

AUC - ROC Curve는 모델의 판단 기준점을 연속적으로 바꾸면서 성능을 측정하였을 때 FPR과 TPR의 변화를 나타낸 것으로, (0,0)과 (1,1)을 잇는 곡선입니다.

***\*ROC\**** (Receiver Operating Characteristic curve)는 FPR (False positive rate)과 TPR (True Positive Rate)을 각각 x, y축으로 놓은 그래프입니다.

- ***\*TPR (True Positive Rate):\**** 레이블이 1인 케이스에 대해 1로 바르게 예측하는 비율
- ***\*FPR (False positive rate):\**** 레이블이 0인 케이스에 대해 1로 틀리게 예측하는 비율

***\*AUC\**** (Area Under the Curve)는 ROC 곡선 아래의 면적을 나타냅니다. AUC 면적의 크기가 클수록 혹은 FPR이 0일 때 TPR이 1에 가까울수록 좋은 모델이라 할 수 있습니다.

![ROC Curve](https://cdn-api.elice.io/api-attachment/attachment/c1e81cbc84184383b30c612cbd94a407/AUC-ROC%20curve.png)

(그림 출처 : https://en.wikipedia.org/wiki/Receiver_operating_characteristic#/media/File:Roc-draft-xkcd-style.svg
)

X축에 해당하는 FPR(False Positive Rate), Y축에 해당하는 TPR(True Positive Rate)는 아래 표와 깊은 관련이 있습니다.

![precision and recall](https://cdn-api.elice.io/api-attachment/attachment/205cb7c9a21b4c00bd7dba0b36ee90b3/precision%20and%20recall.PNG)

(그림 출처 : [Wikipedia - 정밀도와 재현율](https://ko.wikipedia.org/wiki/정밀도와_재현율))

두 변수는 특정 실험 결과가 'Positive' 하게 나왔을 때, 나온 결과 그대로가 정말 믿을만 한 것인지에 대해 알아보기 위해 사용되는 개념입니다.

이번 실습에서는 [실습 7]에서 사용했던 흉부 X선 이미지 dataset을 가지고 분류 모델의 성능을 시각화하는 ROC Curve를 그려보겠습니다.

#### sklearn.metrics 서브 패키지

- `roc_curve(y_true, y_pred)` -> `fpr, tpr`
  : 실제 테스트 데이터의 y값과 모델로 예측하여 얻은 y값 사이의 관계를 파악하기 위해 값을 넣어주면, FPR(False Positive Rate), TPR(True Positive Rate)를 리턴해줍니다.
- `auc(fpr, tpr)` : fpr, tpr로부터 계산된 결과를 ROC Curve에 그릴 수 있도록 영역을 지정합니다.



### 채점에는 2~3분 정도가 소요됩니다.



------

### 실습에 활용된 데이터셋

본 실습에서는 샌 디에고 대학에서 공개한 오픈 데이터셋을 활용합니다.

[Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018), “Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification”, Mendeley Data, V2, doi: 10.17632/rscbjbr9sj.2](https://data.mendeley.com/datasets/rscbjbr9sj/2)

## 지시사항

1. `auc()` 함수에 fpr[i], tpr[i]를 인자로 넣어 각각의 클래스에서의 ROC & AUC 값을 획득하세요.
2. 각 클래스에서의 분류가 잘 되었는지 확인하기 위해서 클래스 별로 색상을 지정합니다.

### Tips

그려진 그래프는 y의 각 클래스에서의 분류가 잘 되었는지에 대한 모델의 사용가능도를 나타내는 ROC curve 입니다. 각 클래스의 영역(area)을 확인하면서, 모델이 괜찮은 성능을 보여주고 있는 지를 판별해 보세요.